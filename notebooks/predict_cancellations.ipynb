{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e325ca-5476-4a4f-8a25-ebfc6cb2baf4",
   "metadata": {},
   "source": [
    "# Decisioning that can be powered using the data shared\n",
    "\n",
    "Based on the data shared, I have listed a few problem statements that can further be explored:\n",
    "\n",
    "1. __Forecasting future demand and growth__ : Estimating future demand/growth is an important activity for OYO as it helps to determine how to plan various operational aspects to address that future demand. For example, call center staffing to accomodate increased customer requests due to surges in bookings, dynamic pricing, expansion to new territories, employing scaleable backend technology etc are all business critical decisions that depend on expected demand. However, since we cannot be conclusive about the span of the data we have (single year, multi year), it would be difficult to create accurate projections of growth. This is because we would not be able to isolate the impacts of seasonality in demand and long term growth using a single years worth of data.\n",
    "\n",
    "2. __Predicting likelihood of booking cancellations__ : As nearly 37% of bookings are cancelled, it is important to be able to predict which bookings are cancelled, to avoid loss in revenue due to making a certain room unavailable. If we flag a booking as likely to cancel, we may want to avoid freezing that particular room for a predetermined amount of time and still accept alternate bookings on the same room. Another way to ensure that a customer is serious about making the booking is to request an advance deposit for risky bookings. The only limiting factor here is that we dont have sufficient historical data per customer to better identify individual cancellation trends.\n",
    "\n",
    "\n",
    "We will now focus on the second use case - creating a model to predict booking cancellations, which should be a straightforward task due to a well sized cancellation rate and sufficient data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed61e7f-df51-40f2-85d9-adc5cea0a0d6",
   "metadata": {},
   "source": [
    "# 1. Data Load and Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d84e78ec-bcff-4a1e-a615-d886fd595fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import standard libraries\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score,confusion_matrix\n",
    "\n",
    "#set seed for reproducibility\n",
    "np.random.seed(2021)\n",
    "\n",
    "#load in constants such as data paths and locations\n",
    "from constants import TRAIN_DIR,ARTIFACTS_PATH\n",
    "#load the raw data\n",
    "data = pd.read_csv(TRAIN_DIR)\n",
    "\n",
    "#cast to numeric data\n",
    "data['chidren'] = data['chidren'].fillna('0').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06867e53-36ba-4a88-b51a-a12bfb6efa6d",
   "metadata": {},
   "source": [
    "To minimize training serving skew, it is a good practice to have a single data preparation function module that can be called during offline training and online inference. In this case since inference is offline, we will not worry about the case where we don't have labels on eval data. This is a function likely to be reused in a production setting, so we may want to enrich this function with better documentation\n",
    "\n",
    "Here, we will split our data randomly rather than by time, to ensure the model learns seasonal trends as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67fe30b6-79b3-4dc5-9ce7-bd620c4a8db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data_type = 'train',\n",
    "                 data = None,\n",
    "                 artifacts_path = '',\n",
    "                 cat_cols = [],\n",
    "                 num_cols = [],\n",
    "                 target_col = ''\n",
    "                 ):\n",
    "    '''\n",
    "        Description : Function to transform raw booking transaction data into modelling data to\n",
    "                      be used in prediction of customer cancellations\n",
    "        \n",
    "        Parameters : \n",
    "                \n",
    "                data_type (str) : ['train','test'] - specify train or test to help the function\n",
    "                                                     decide if it needs to train data transformers or \n",
    "                                                     load pre built transformers\n",
    "                                                     \n",
    "                data (pd.DataFrame) - input pandas df on which we want to apply data transformation\n",
    "                \n",
    "                artifacts_path - path on hard disk to save data transformation artifacts\n",
    "                \n",
    "                cat_cols - list of categorical columns in the input data\n",
    "                \n",
    "                num_cols - list of numerical columns in the input data\n",
    "                \n",
    "                target_col - target column in the input data. no transformation will occur on this column\n",
    "                \n",
    "        Returns :\n",
    "                \n",
    "                out (pd.DataFrame) - transformed data ready to be used for modelling purposes\n",
    "    \n",
    "    '''\n",
    "    #common feature engineering\n",
    "    #check if the requested room was the same as the assigned room.\n",
    "    data['same_room_flag'] = 1\n",
    "    data['same_room_flag'][data.roomType == data.assignedType] = 0\n",
    "    \n",
    "    custom_features = ['same_room_flag']\n",
    "    \n",
    "    if data_type == 'train':\n",
    "        #apply mean imputations on numeric data, add a new\n",
    "        imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean').fit(data[num_cols])\n",
    "        imputed_num_data = imp_mean.transform(data[num_cols])\n",
    "        imp_cat = SimpleImputer(missing_values=np.nan, strategy='constant',fill_value = 'missing').fit(data[cat_cols])\n",
    "        imputed_cat_data = imp_cat.transform(data[cat_cols])\n",
    "        \n",
    "        #get scaled values of numeric features\n",
    "        standard_scaler = StandardScaler().fit(imputed_num_data)\n",
    "        numerical_features_df = pd.DataFrame(standard_scaler.transform(imputed_num_data),columns = num_cols)\n",
    "        print('numerical_features_df data shape {}'.format(numerical_features_df.shape))\n",
    "\n",
    "        #get dummies for categorical features\n",
    "        ohe_encoder = OneHotEncoder(handle_unknown='ignore',sparse = False, drop = 'first').fit(imputed_cat_data)\n",
    "        categorical_features_df = pd.DataFrame(ohe_encoder.transform(imputed_cat_data),columns = ohe_encoder.get_feature_names_out(cat_cols))\n",
    "        print('categorical_features_df data shape {}'.format(categorical_features_df.shape))\n",
    "\n",
    "        #save our data transformers\n",
    "        joblib.dump(ohe_encoder,artifacts_path+'ohe_obj.pkl')\n",
    "        joblib.dump(standard_scaler,artifacts_path+'standard_scaler.pkl')\n",
    "        joblib.dump(imp_mean,artifacts_path+'imp_mean.pkl')\n",
    "        joblib.dump(imp_cat,artifacts_path+'imp_cat.pkl')\n",
    "\n",
    "    elif data_type == 'test':\n",
    "        #load our data transformers and call the transform function on the test data\n",
    "        ohe_encoder = joblib.load(artifacts_path+'ohe_obj.pkl')\n",
    "        standard_scaler = joblib.load(artifacts_path+'standard_scaler.pkl')\n",
    "        imp_mean = joblib.load(artifacts_path+'imp_mean.pkl')\n",
    "        imp_cat = joblib.load(artifacts_path+'imp_cat.pkl')\n",
    "        \n",
    "        #call transform\n",
    "        imp_cat_df = imp_cat.transform(data[cat_cols])\n",
    "        imp_num_df = imp_mean.transform(data[num_cols])\n",
    "        categorical_features_df = pd.DataFrame(ohe_encoder.transform(imp_cat_df),columns = ohe_encoder.get_feature_names_out(cat_cols))\n",
    "        numerical_features_df = pd.DataFrame(standard_scaler.transform(imp_num_df),columns = num_cols)\n",
    "        print('categorical_features_df data shape {}'.format(categorical_features_df.shape))\n",
    "        print('numerical_features_df data shape {}'.format(numerical_features_df.shape))\n",
    "    \n",
    "    #concat data together\n",
    "    out = pd.concat([numerical_features_df,categorical_features_df,data[custom_features + [target_col]].reset_index(drop = True)], axis = 1)\n",
    "    \n",
    "    print('processed data shape {}'.format(out.shape))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "511dfa02-8acc-4e6d-8d9f-c05a583da437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-f8933fc79352>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['same_room_flag'][data.roomType == data.assignedType] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical_features_df data shape (95512, 11)\n",
      "categorical_features_df data shape (95512, 213)\n",
      "processed data shape (95512, 226)\n",
      "categorical_features_df data shape (23878, 213)\n",
      "numerical_features_df data shape (23878, 11)\n",
      "processed data shape (23878, 226)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-f8933fc79352>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['same_room_flag'][data.roomType == data.assignedType] = 0\n",
      "/Users/vishwanathprudhivi/opt/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:170: UserWarning: Found unknown categories in columns [7] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#define cat and numeric column lists for modelling. for now we will exclude country as it may need embeddings\n",
    "#other variables excluded - 'arrivalDay' since we dont know the day of week in the absence of a year column\n",
    "cat_cols = ['arrivalMonth','segment','roomType','assignedType','customerSegment','deposit','type','country']\n",
    "num_cols = ['time2Checkin','numberWeekendnights','numberNights','adults','chidren','changesFlag',\\\n",
    "            'repeatFlag','historicCancellations','historicBookings','waitingDays','numberofRequests']\n",
    "target = 'canceledFlag'\n",
    "\n",
    "#adopt an 80-20 split for train and test data\n",
    "train_df, test_df = train_test_split(data, test_size=0.2, random_state=0)\n",
    "\n",
    "#train the transformers on training data, transform the data and save the artifacts to disk\n",
    "train_df = prepare_data(data_type = 'train',\n",
    "                 data = train_df,\n",
    "                 artifacts_path = ARTIFACTS_PATH,\n",
    "                 cat_cols = cat_cols,\n",
    "                 num_cols = num_cols,\n",
    "                 target_col = target)\n",
    "\n",
    "#load the transformers from disk, and transform the test data\n",
    "test_df = prepare_data(data_type = 'test',\n",
    "                 data = test_df,\n",
    "                 artifacts_path = ARTIFACTS_PATH,\n",
    "                 cat_cols = cat_cols,\n",
    "                 num_cols = num_cols,\n",
    "                 target_col = target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b64c861-6415-4aeb-a82e-97144013c4cb",
   "metadata": {},
   "source": [
    "Let's visually inspect the final transformed data to pick up any errors in data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b11a9fd6-3763-400c-aa8a-4c2d00d71b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time2Checkin</th>\n",
       "      <th>numberWeekendnights</th>\n",
       "      <th>numberNights</th>\n",
       "      <th>adults</th>\n",
       "      <th>chidren</th>\n",
       "      <th>changesFlag</th>\n",
       "      <th>repeatFlag</th>\n",
       "      <th>historicCancellations</th>\n",
       "      <th>historicBookings</th>\n",
       "      <th>waitingDays</th>\n",
       "      <th>...</th>\n",
       "      <th>country_UZB</th>\n",
       "      <th>country_VEN</th>\n",
       "      <th>country_VGB</th>\n",
       "      <th>country_VNM</th>\n",
       "      <th>country_ZAF</th>\n",
       "      <th>country_ZMB</th>\n",
       "      <th>country_ZWE</th>\n",
       "      <th>country_missing</th>\n",
       "      <th>same_room_flag</th>\n",
       "      <th>canceledFlag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.551200e+04</td>\n",
       "      <td>9.551200e+04</td>\n",
       "      <td>9.551200e+04</td>\n",
       "      <td>9.551200e+04</td>\n",
       "      <td>9.551200e+04</td>\n",
       "      <td>9.551200e+04</td>\n",
       "      <td>9.551200e+04</td>\n",
       "      <td>9.551200e+04</td>\n",
       "      <td>9.551200e+04</td>\n",
       "      <td>9.551200e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>95512.000000</td>\n",
       "      <td>95512.000000</td>\n",
       "      <td>95512.000000</td>\n",
       "      <td>95512.000000</td>\n",
       "      <td>95512.000000</td>\n",
       "      <td>95512.000000</td>\n",
       "      <td>95512.000000</td>\n",
       "      <td>95512.000000</td>\n",
       "      <td>95512.000000</td>\n",
       "      <td>95512.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.701687e-16</td>\n",
       "      <td>1.664495e-15</td>\n",
       "      <td>-4.048980e-16</td>\n",
       "      <td>-4.423084e-15</td>\n",
       "      <td>-5.195947e-16</td>\n",
       "      <td>1.761290e-16</td>\n",
       "      <td>-4.863325e-15</td>\n",
       "      <td>1.135793e-15</td>\n",
       "      <td>-8.644845e-16</td>\n",
       "      <td>-8.302913e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.004209</td>\n",
       "      <td>0.124738</td>\n",
       "      <td>0.369378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004576</td>\n",
       "      <td>0.014469</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>0.007235</td>\n",
       "      <td>0.026278</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>0.064740</td>\n",
       "      <td>0.330424</td>\n",
       "      <td>0.482639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-9.727476e-01</td>\n",
       "      <td>-9.267400e-01</td>\n",
       "      <td>-1.305935e+00</td>\n",
       "      <td>-3.178095e+00</td>\n",
       "      <td>-2.611050e-01</td>\n",
       "      <td>-3.401628e-01</td>\n",
       "      <td>-1.824813e-01</td>\n",
       "      <td>-1.029315e-01</td>\n",
       "      <td>-9.175440e-02</td>\n",
       "      <td>-1.311692e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.038555e-01</td>\n",
       "      <td>-9.267400e-01</td>\n",
       "      <td>-7.838474e-01</td>\n",
       "      <td>2.478571e-01</td>\n",
       "      <td>-2.611050e-01</td>\n",
       "      <td>-3.401628e-01</td>\n",
       "      <td>-1.824813e-01</td>\n",
       "      <td>-1.029315e-01</td>\n",
       "      <td>-9.175440e-02</td>\n",
       "      <td>-1.311692e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.253280e-01</td>\n",
       "      <td>7.330283e-02</td>\n",
       "      <td>-2.617598e-01</td>\n",
       "      <td>2.478571e-01</td>\n",
       "      <td>-2.611050e-01</td>\n",
       "      <td>-3.401628e-01</td>\n",
       "      <td>-1.824813e-01</td>\n",
       "      <td>-1.029315e-01</td>\n",
       "      <td>-9.175440e-02</td>\n",
       "      <td>-1.311692e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.285151e-01</td>\n",
       "      <td>1.073346e+00</td>\n",
       "      <td>2.603277e-01</td>\n",
       "      <td>2.478571e-01</td>\n",
       "      <td>-2.611050e-01</td>\n",
       "      <td>-3.401628e-01</td>\n",
       "      <td>-1.824813e-01</td>\n",
       "      <td>-1.029315e-01</td>\n",
       "      <td>-9.175440e-02</td>\n",
       "      <td>-1.311692e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.942444e+00</td>\n",
       "      <td>1.807407e+01</td>\n",
       "      <td>2.479844e+01</td>\n",
       "      <td>9.103558e+01</td>\n",
       "      <td>7.283109e+00</td>\n",
       "      <td>3.195111e+01</td>\n",
       "      <td>5.480013e+00</td>\n",
       "      <td>3.065280e+01</td>\n",
       "      <td>4.827422e+01</td>\n",
       "      <td>2.215761e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       time2Checkin  numberWeekendnights  numberNights        adults  \\\n",
       "count  9.551200e+04         9.551200e+04  9.551200e+04  9.551200e+04   \n",
       "mean  -1.701687e-16         1.664495e-15 -4.048980e-16 -4.423084e-15   \n",
       "std    1.000005e+00         1.000005e+00  1.000005e+00  1.000005e+00   \n",
       "min   -9.727476e-01        -9.267400e-01 -1.305935e+00 -3.178095e+00   \n",
       "25%   -8.038555e-01        -9.267400e-01 -7.838474e-01  2.478571e-01   \n",
       "50%   -3.253280e-01         7.330283e-02 -2.617598e-01  2.478571e-01   \n",
       "75%    5.285151e-01         1.073346e+00  2.603277e-01  2.478571e-01   \n",
       "max    5.942444e+00         1.807407e+01  2.479844e+01  9.103558e+01   \n",
       "\n",
       "            chidren   changesFlag    repeatFlag  historicCancellations  \\\n",
       "count  9.551200e+04  9.551200e+04  9.551200e+04           9.551200e+04   \n",
       "mean  -5.195947e-16  1.761290e-16 -4.863325e-15           1.135793e-15   \n",
       "std    1.000005e+00  1.000005e+00  1.000005e+00           1.000005e+00   \n",
       "min   -2.611050e-01 -3.401628e-01 -1.824813e-01          -1.029315e-01   \n",
       "25%   -2.611050e-01 -3.401628e-01 -1.824813e-01          -1.029315e-01   \n",
       "50%   -2.611050e-01 -3.401628e-01 -1.824813e-01          -1.029315e-01   \n",
       "75%   -2.611050e-01 -3.401628e-01 -1.824813e-01          -1.029315e-01   \n",
       "max    7.283109e+00  3.195111e+01  5.480013e+00           3.065280e+01   \n",
       "\n",
       "       historicBookings   waitingDays  ...   country_UZB   country_VEN  \\\n",
       "count      9.551200e+04  9.551200e+04  ...  95512.000000  95512.000000   \n",
       "mean      -8.644845e-16 -8.302913e-16  ...      0.000021      0.000209   \n",
       "std        1.000005e+00  1.000005e+00  ...      0.004576      0.014469   \n",
       "min       -9.175440e-02 -1.311692e-01  ...      0.000000      0.000000   \n",
       "25%       -9.175440e-02 -1.311692e-01  ...      0.000000      0.000000   \n",
       "50%       -9.175440e-02 -1.311692e-01  ...      0.000000      0.000000   \n",
       "75%       -9.175440e-02 -1.311692e-01  ...      0.000000      0.000000   \n",
       "max        4.827422e+01  2.215761e+01  ...      1.000000      1.000000   \n",
       "\n",
       "        country_VGB   country_VNM   country_ZAF   country_ZMB   country_ZWE  \\\n",
       "count  95512.000000  95512.000000  95512.000000  95512.000000  95512.000000   \n",
       "mean       0.000010      0.000052      0.000691      0.000010      0.000042   \n",
       "std        0.003236      0.007235      0.026278      0.003236      0.006471   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       country_missing  same_room_flag  canceledFlag  \n",
       "count     95512.000000    95512.000000  95512.000000  \n",
       "mean          0.004209        0.124738      0.369378  \n",
       "std           0.064740        0.330424      0.482639  \n",
       "min           0.000000        0.000000      0.000000  \n",
       "25%           0.000000        0.000000      0.000000  \n",
       "50%           0.000000        0.000000      0.000000  \n",
       "75%           0.000000        0.000000      1.000000  \n",
       "max           1.000000        1.000000      1.000000  \n",
       "\n",
       "[8 rows x 226 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd2d266-6eb3-457a-b8b7-818aadfe4cf2",
   "metadata": {},
   "source": [
    "## 2. Baseline Performance\n",
    "\n",
    "Let's use a simple baseline such as logistic regression to set a benchmark to beat. Here we can see that while the baseline model generates a balanced accuracy of around 80%, the model has a high false negative rate which we need to try and improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "68cc7296-98f6-4f5d-8338-437200b45cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.8098040036854008\n",
      "Train AUC:  0.7735447614650413\n",
      "Train confusion matrix: \n",
      " [[54952  5280]\n",
      " [12886 22394]]\n",
      "Test Accuracy:  0.8065164586648798\n",
      "Test AUC:  0.7717503602014636\n",
      "Test confusion matrix: \n",
      " [[13595  1339]\n",
      " [ 3281  5663]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "model.fit(train_df.drop(columns = target), train_df[target])\n",
    "\n",
    "result = model.score(train_df.drop(columns = target), train_df[target])\n",
    "print('Train Accuracy: ',result)\n",
    "print('Train AUC: ',roc_auc_score(train_df[target],model.predict(train_df.drop(columns = target))))\n",
    "print('Train confusion matrix: \\n',confusion_matrix(train_df[target],model.predict(train_df.drop(columns = target))))\n",
    "\n",
    "result = model.score(test_df.drop(columns = target), test_df[target])\n",
    "print('Test Accuracy: ',result)\n",
    "print('Test AUC: ',roc_auc_score(test_df[target],model.predict(test_df.drop(columns = target))))\n",
    "print('Test confusion matrix: \\n',confusion_matrix(test_df[target],model.predict(test_df.drop(columns = target))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace76c65-bf20-417b-b91b-d6da4673000a",
   "metadata": {},
   "source": [
    "Let's check the coefficients to understand the main predictors of cancellations. It seems that the type of room and deposit are heavily influencing the predictions, while month of booking is moderately important. Historical bookings and cancellations also appear in the top drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fa006ab9-b0e4-4a9f-9e7d-834ed86829a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coef</th>\n",
       "      <th>coef_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>deposit_Non Refund</td>\n",
       "      <td>[5.042751505660763]</td>\n",
       "      <td>5.042752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>country_HKG</td>\n",
       "      <td>[2.2257185473506835]</td>\n",
       "      <td>2.225719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>same_room_flag</td>\n",
       "      <td>[-2.1364754406200017]</td>\n",
       "      <td>2.136475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>country_ARE</td>\n",
       "      <td>[2.0560608522859076]</td>\n",
       "      <td>2.056061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>country_SRB</td>\n",
       "      <td>[-1.8505537078048058]</td>\n",
       "      <td>1.850554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>country_MAC</td>\n",
       "      <td>[1.7527320001434257]</td>\n",
       "      <td>1.752732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>assignedType_P</td>\n",
       "      <td>[1.7216432098593155]</td>\n",
       "      <td>1.721643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>roomType_P</td>\n",
       "      <td>[1.7216432098593155]</td>\n",
       "      <td>1.721643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>historicCancellations</td>\n",
       "      <td>[1.6253694374070138]</td>\n",
       "      <td>1.625369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>country_JEY</td>\n",
       "      <td>[1.4972888246526672]</td>\n",
       "      <td>1.497289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>country_PHL</td>\n",
       "      <td>[1.4591000501428515]</td>\n",
       "      <td>1.459100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>country_ISL</td>\n",
       "      <td>[-1.4392691471485402]</td>\n",
       "      <td>1.439269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>country_AGO</td>\n",
       "      <td>[1.438609177227984]</td>\n",
       "      <td>1.438609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>country_MDV</td>\n",
       "      <td>[1.4270065417502686]</td>\n",
       "      <td>1.427007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>country_BHR</td>\n",
       "      <td>[1.4265206536231614]</td>\n",
       "      <td>1.426521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>country_BOL</td>\n",
       "      <td>[-1.3855826464028422]</td>\n",
       "      <td>1.385583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>country_NGA</td>\n",
       "      <td>[1.3771770712384828]</td>\n",
       "      <td>1.377177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>country_PAN</td>\n",
       "      <td>[-1.3504746485544337]</td>\n",
       "      <td>1.350475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>country_IDN</td>\n",
       "      <td>[1.2693266034338109]</td>\n",
       "      <td>1.269327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>country_TZA</td>\n",
       "      <td>[1.2585059583081726]</td>\n",
       "      <td>1.258506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>country_AND</td>\n",
       "      <td>[1.244457870326598]</td>\n",
       "      <td>1.244458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>country_PRT</td>\n",
       "      <td>[1.2400774359421707]</td>\n",
       "      <td>1.240077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>country_NZL</td>\n",
       "      <td>[-1.2024719256910763]</td>\n",
       "      <td>1.202472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>country_GIB</td>\n",
       "      <td>[1.1695764615360482]</td>\n",
       "      <td>1.169576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>roomType_B</td>\n",
       "      <td>[-1.1592805962656223]</td>\n",
       "      <td>1.159281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>segment_onl</td>\n",
       "      <td>[1.1418527138159558]</td>\n",
       "      <td>1.141853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>country_LTU</td>\n",
       "      <td>[-1.1195490544592646]</td>\n",
       "      <td>1.119549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>assignedType_I</td>\n",
       "      <td>[-1.1101572312473906]</td>\n",
       "      <td>1.110157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>country_QAT</td>\n",
       "      <td>[1.0988763273478224]</td>\n",
       "      <td>1.098876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>country_GGY</td>\n",
       "      <td>[1.0791407632786594]</td>\n",
       "      <td>1.079141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  features                   coef  coef_abs\n",
       "51      deposit_Non Refund    [5.042751505660763]  5.042752\n",
       "120            country_HKG   [2.2257185473506835]  2.225719\n",
       "224         same_room_flag  [-2.1364754406200017]  2.136475\n",
       "58             country_ARE   [2.0560608522859076]  2.056061\n",
       "195            country_SRB  [-1.8505537078048058]  1.850554\n",
       "153            country_MAC   [1.7527320001434257]  1.752732\n",
       "48          assignedType_P   [1.7216432098593155]  1.721643\n",
       "37              roomType_P   [1.7216432098593155]  1.721643\n",
       "7    historicCancellations   [1.6253694374070138]  1.625369\n",
       "134            country_JEY   [1.4972888246526672]  1.497289\n",
       "179            country_PHL   [1.4591000501428515]  1.459100\n",
       "130            country_ISL  [-1.4392691471485402]  1.439269\n",
       "54             country_AGO    [1.438609177227984]  1.438609\n",
       "155            country_MDV   [1.4270065417502686]  1.427007\n",
       "72             country_BHR   [1.4265206536231614]  1.426521\n",
       "76             country_BOL  [-1.3855826464028422]  1.385583\n",
       "169            country_NGA   [1.3771770712384828]  1.377177\n",
       "177            country_PAN  [-1.3504746485544337]  1.350475\n",
       "124            country_IDN   [1.2693266034338109]  1.269327\n",
       "210            country_TZA   [1.2585059583081726]  1.258506\n",
       "57             country_AND    [1.244457870326598]  1.244458\n",
       "183            country_PRT   [1.2400774359421707]  1.240077\n",
       "174            country_NZL  [-1.2024719256910763]  1.202472\n",
       "114            country_GIB   [1.1695764615360482]  1.169576\n",
       "29              roomType_B  [-1.1592805962656223]  1.159281\n",
       "27             segment_onl   [1.1418527138159558]  1.141853\n",
       "150            country_LTU  [-1.1195490544592646]  1.119549\n",
       "45          assignedType_I  [-1.1101572312473906]  1.110157\n",
       "185            country_QAT   [1.0988763273478224]  1.098876\n",
       "112            country_GGY   [1.0791407632786594]  1.079141"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract model coefficients and sort them according to magnitude\n",
    "coeff = pd.DataFrame(zip(train_df.drop(columns = target).columns, np.transpose(model.coef_)), columns=['features', 'coef']) \n",
    "coeff['coef_abs'] = coeff['coef'].apply(lambda x: abs(x[0]))\n",
    "coeff.sort_values(by = 'coef_abs', ascending = False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd50e74-16a3-4f55-b391-655020e9944d",
   "metadata": {},
   "source": [
    "# 3. Non linear Algorithmic Performance and Feature selection, engineering\n",
    "\n",
    "We will now try and improve upon our baseline using a combination of non linear algorithms, feature engineering and selection. Recall from DIDQ that we observed many correlated variables. We will use l1 penalties to filter out variables, we can use xgboost with l2 norm for better performance and finally think of some feature engineering.\n",
    "\n",
    "## Feature Engineering:\n",
    "\n",
    "1. Difference between room type and assigned room type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "13fc57a9-f561-49ca-9eeb-c187781a93f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coef</th>\n",
       "      <th>coef_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>deposit_Non Refund</td>\n",
       "      <td>0.413365</td>\n",
       "      <td>0.413365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>country_PRT</td>\n",
       "      <td>0.207337</td>\n",
       "      <td>0.207337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>segment_onl</td>\n",
       "      <td>0.193300</td>\n",
       "      <td>0.193300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>same_room_flag</td>\n",
       "      <td>-0.134129</td>\n",
       "      <td>0.134129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>numberofRequests</td>\n",
       "      <td>-0.078160</td>\n",
       "      <td>0.078160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>time2Checkin</td>\n",
       "      <td>0.067308</td>\n",
       "      <td>0.067308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>changesFlag</td>\n",
       "      <td>-0.026483</td>\n",
       "      <td>0.026483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>type_R</td>\n",
       "      <td>-0.021206</td>\n",
       "      <td>0.021206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adults</td>\n",
       "      <td>0.013091</td>\n",
       "      <td>0.013091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>repeatFlag</td>\n",
       "      <td>-0.012052</td>\n",
       "      <td>0.012052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>historicCancellations</td>\n",
       "      <td>0.011536</td>\n",
       "      <td>0.011536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>numberNights</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.011300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chidren</td>\n",
       "      <td>0.006748</td>\n",
       "      <td>0.006748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>numberWeekendnights</td>\n",
       "      <td>0.006502</td>\n",
       "      <td>0.006502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>historicBookings</td>\n",
       "      <td>-0.000212</td>\n",
       "      <td>0.000212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>country_MKD</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>country_LIE</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>country_LKA</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>country_LTU</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>country_LUX</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>country_LVA</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>country_MAC</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>country_MAR</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>country_MDV</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>country_MEX</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>country_NCL</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>country_MLI</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>country_NAM</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>country_LBY</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>country_MLT</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>country_MMR</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>country_MNE</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>country_MOZ</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>country_MUS</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>country_MWI</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>country_MYS</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>country_MYT</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>country_LCA</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>country_KWT</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>country_LBN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  features      coef  coef_abs\n",
       "51      deposit_Non Refund  0.413365  0.413365\n",
       "183            country_PRT  0.207337  0.207337\n",
       "27             segment_onl  0.193300  0.193300\n",
       "224         same_room_flag -0.134129  0.134129\n",
       "10        numberofRequests -0.078160  0.078160\n",
       "0             time2Checkin  0.067308  0.067308\n",
       "5              changesFlag -0.026483  0.026483\n",
       "53                  type_R -0.021206  0.021206\n",
       "3                   adults  0.013091  0.013091\n",
       "6               repeatFlag -0.012052  0.012052\n",
       "7    historicCancellations  0.011536  0.011536\n",
       "2             numberNights  0.011300  0.011300\n",
       "4                  chidren  0.006748  0.006748\n",
       "1      numberWeekendnights  0.006502  0.006502\n",
       "8         historicBookings -0.000212  0.000212\n",
       "157            country_MKD -0.000000  0.000000\n",
       "148            country_LIE  0.000000  0.000000\n",
       "149            country_LKA -0.000000  0.000000\n",
       "150            country_LTU -0.000000  0.000000\n",
       "151            country_LUX  0.000000  0.000000\n",
       "152            country_LVA -0.000000  0.000000\n",
       "153            country_MAC  0.000000  0.000000\n",
       "154            country_MAR  0.000000  0.000000\n",
       "155            country_MDV  0.000000  0.000000\n",
       "156            country_MEX -0.000000  0.000000\n",
       "168            country_NCL -0.000000  0.000000\n",
       "158            country_MLI -0.000000  0.000000\n",
       "167            country_NAM -0.000000  0.000000\n",
       "146            country_LBY -0.000000  0.000000\n",
       "159            country_MLT -0.000000  0.000000\n",
       "160            country_MMR -0.000000  0.000000\n",
       "161            country_MNE  0.000000  0.000000\n",
       "162            country_MOZ -0.000000  0.000000\n",
       "163            country_MUS -0.000000  0.000000\n",
       "164            country_MWI -0.000000  0.000000\n",
       "165            country_MYS -0.000000  0.000000\n",
       "166            country_MYT  0.000000  0.000000\n",
       "147            country_LCA -0.000000  0.000000\n",
       "143            country_KWT  0.000000  0.000000\n",
       "145            country_LBN  0.000000  0.000000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train a Lasso regression model and use the coefficients for feature selection\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model = Lasso(alpha=0.01)\n",
    "model.fit(train_df.drop(columns = target), train_df[target])\n",
    "\n",
    "coeff = pd.DataFrame(zip(train_df.drop(columns = target).columns, np.transpose(model.coef_)), columns=['features', 'coef']) \n",
    "coeff['coef_abs'] = coeff['coef'].apply(lambda x: abs(x))\n",
    "coeff.sort_values(by = 'coef_abs', ascending = False).head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c69a1d-5af3-4cbe-adcd-f760902c6b6a",
   "metadata": {},
   "source": [
    "# Observations:\n",
    "1. Using the full list of features we get a model with 83% accuracy and 80% AUC\n",
    "2. Using the filtered list of features obtained from fitting a Lasso model, we get a model with 82.5% accuracy and 79% AUC\n",
    "3. Thus, by using only 13 out of 55 total features, we are able to get a similar model with minimal degradation in model performance. \n",
    "4. After adding encoded country variables, we observe a 5% improvement in accuracy and 4% improvement in AUC, however we have 225 variables in the model\n",
    "5. After applying lasso once again, we observe that we only need one country variable 'country_PRT' and we observe similar model performance\n",
    "6. We have been able to significantly reduce the False Negative Rate (25%) compared to the baseline (37%), which is satisfactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cd966b38-75f0-42f2-9ec1-f5a1ad8db42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishwanathprudhivi/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:57:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Train Accuracy:  0.8498303878046738\n",
      "Train AUC:  0.8306024396520906\n",
      "Train confusion matrix: \n",
      " [[54462  5770]\n",
      " [ 8573 26707]]\n",
      "Test Accuracy:  0.8414858865901667\n",
      "Test AUC:  0.8224882161893967\n",
      "Test confusion matrix: \n",
      " [[13414  1520]\n",
      " [ 2265  6679]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "#feature list to be passed to the model\n",
    "#features = [col for col in train_df.columns if target not in col]\n",
    "features = ['deposit_Non Refund','segment_onl','numberofRequests','time2Checkin',\\\n",
    "            'changesFlag','historicCancellations','adults','chidren','numberNights',\\\n",
    "            'numberWeekendnights','country_PRT','repeatFlag','same_room_flag']\n",
    "\n",
    "#we will apply only L2 penalty for regularization as L1 has already been applied for feature selection\n",
    "model = XGBClassifier(reg_lambda = 0.01).fit(train_df[features], train_df[target])\n",
    "result = model.score(train_df[features], train_df[target])\n",
    "print('Train Accuracy: ',result)\n",
    "print('Train AUC: ',roc_auc_score(train_df[target],model.predict(train_df[features])))\n",
    "print('Train confusion matrix: \\n',confusion_matrix(train_df[target],model.predict(train_df[features])))\n",
    "\n",
    "result = model.score(test_df[features], test_df[target])\n",
    "print('Test Accuracy: ',result)\n",
    "print('Test AUC: ',roc_auc_score(test_df[target],model.predict(test_df[features])))\n",
    "print('Test confusion matrix: \\n',confusion_matrix(test_df[target],model.predict(test_df[features])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2a3219-35bc-4c26-97d2-22765340f2ca",
   "metadata": {},
   "source": [
    "A look at the feature importances by gain generated by the xgboost model agrees with the coefficients reported by the logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b3e6195e-4d9d-442d-ae5c-6c2650347053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deposit_Non Refund</th>\n",
       "      <td>1738.854549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>same_room_flag</th>\n",
       "      <td>83.756869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment_onl</th>\n",
       "      <td>69.911758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country_PRT</th>\n",
       "      <td>48.949408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>historicCancellations</th>\n",
       "      <td>43.079593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numberofRequests</th>\n",
       "      <td>29.521797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>repeatFlag</th>\n",
       "      <td>21.098753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>changesFlag</th>\n",
       "      <td>12.209634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time2Checkin</th>\n",
       "      <td>10.697330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adults</th>\n",
       "      <td>6.116777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chidren</th>\n",
       "      <td>5.510609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numberWeekendnights</th>\n",
       "      <td>5.104597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numberNights</th>\n",
       "      <td>4.302386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             score\n",
       "deposit_Non Refund     1738.854549\n",
       "same_room_flag           83.756869\n",
       "segment_onl              69.911758\n",
       "country_PRT              48.949408\n",
       "historicCancellations    43.079593\n",
       "numberofRequests         29.521797\n",
       "repeatFlag               21.098753\n",
       "changesFlag              12.209634\n",
       "time2Checkin             10.697330\n",
       "adults                    6.116777\n",
       "chidren                   5.510609\n",
       "numberWeekendnights       5.104597\n",
       "numberNights              4.302386"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract feature importances and store them in a pandas df\n",
    "feature_importances = model.get_booster().get_score(importance_type='gain')\n",
    "keys = list(feature_importances.keys())\n",
    "values = list(feature_importances.values())\n",
    "feature_importances_df = pd.DataFrame(data=values, index=keys, columns=[\"score\"]).sort_values(by = \"score\", ascending=False)\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ec7d7e-183f-4667-adce-16c9f53324c5",
   "metadata": {},
   "source": [
    "# 4. Conclusions\n",
    "\n",
    "1. Using the final model, we will be able to identify 75% (recall) of potential cancellations. Correct handling of such bookings will guarantee increased revenues for OYO, as well as improved customer experience with bookings as more rooms could potentially be listed as available. We can potentially bring down the cancellation rate from 37% to 10% per annum with the correct intervention strategies.\n",
    "\n",
    "2. The most predictive features used in the model are features that are generated directly at the time of manual entry in the online/app session. We don't see the impact of internally defined customer segments and demographic data on cancellations. This is a very critical point since this model is most likely going to be embedded on the website/app itself and will serve real time predictions. As a result, additional latency generated due to hits on OYOs internal databases will be eliminated.\n",
    "\n",
    "3. Given the requirements of the model (real time predictions), it is also important to have a lighter model with lesser compexity and input feature space for low latency predictions. This is why I would recommend deploying the model with 13 features over the 225 feature model. Usually we need to accept a tradeoff between model accuracy and low latency predictions, however in our case the degradation of model performance is negligible.\n",
    "\n",
    "# 5. Next Steps\n",
    "\n",
    "1. Explore neural networks as a way to improve model accuracy.\n",
    "2. Advanced Feature engineering such as embeddings for country variables\n",
    "3. Data collection to build richer customer histories to explore sequential aspects of customer cancellation behaviour\n",
    "3. Model deployment and integration with OYO ecosystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5eac04a5-5737-4e52-b098-6c873b8a85bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/vishwanathprudhivi/Desktop/Work/Interview/OYO/oyo_case_study/artifacts/model.pkl']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the final model to disk\n",
    "joblib.dump(model,ARTIFACTS_PATH+'model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
